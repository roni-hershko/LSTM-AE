# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bYkEyHe0LbVCu6mBuq_sp2CrUSfdbFuh
"""

### LSTM Autoencoder Homework 2 - Template

# Imports
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt

# Check for CUDA
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

### 1. Synthetic Data Generation
def generate_synthetic_data(num_sequences=10000, sequence_length=50):
    data = np.random.rand(num_sequences, sequence_length)
    for seq in data:
        i = np.random.randint(20, 31)
        seq[i-5:i+6] *= 0.1
    return data

def split_data(data, train_ratio=0.6, val_ratio=0.2):
    num_train = int(len(data) * train_ratio)
    num_val = int(len(data) * val_ratio)
    train_data = data[:num_train]
    val_data = data[num_train:num_train + num_val]
    test_data = data[num_train + num_val:]
    return train_data, val_data, test_data

### 2. Dataset Class
class SequenceDataset(Dataset):
    def __init__(self, sequences):
        self.sequences = torch.tensor(sequences, dtype=torch.float32)

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return self.sequences[idx].to(device)

### 3. LSTM Autoencoder
class LSTMAutoencoder(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(LSTMAutoencoder, self).__init__()
        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.decoder = nn.LSTM(hidden_size, input_size, batch_first=True)

    def forward(self, x):
        # Encoder
        enc_out, (enc_hn, enc_cn) = self.encoder(x)
        # Decoder
        output, (dec_hn,dec_cn) = self.decoder(enc_out)
        return output

### 4. Training Loop
def train_model(model, dataloader, optimizer, criterion, num_epochs=20):
    model.train()
    for epoch in range(num_epochs):
        epoch_loss = 0
        for batch in dataloader:
            optimizer.zero_grad()
            reconstructed = model(batch)
            loss = criterion(reconstructed, batch)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
        print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader):.4f}")

### 5. Grid Search for Hyperparameters
def grid_search(train_data, val_data, hidden_sizes, learning_rates, gradient_clipping_values, num_epochs=20):
    best_model = None
    best_loss = float('inf')
    best_params = None

    for hidden_size in hidden_sizes:
        for lr in learning_rates:
            for clip in gradient_clipping_values:
                print(f"Testing hidden_size={hidden_size}, lr={lr}, clip={clip}")

                # Define model, optimizer, and loss function
                model = LSTMAutoencoder(input_size=1, hidden_size=hidden_size).to(device)
                optimizer = optim.Adam(model.parameters(), lr=lr)
                criterion = nn.MSELoss()

                # Prepare datasets and dataloaders
                train_dataset = SequenceDataset(train_data)
                train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)

                val_dataset = SequenceDataset(val_data)
                val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)

                # Train the model
                model.train()
                for epoch in range(num_epochs):
                    for batch in train_loader:
                        optimizer.zero_grad()
                        reconstructed = model(batch)
                        loss = criterion(reconstructed, batch)
                        loss.backward()
                        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)
                        optimizer.step()

                # Evaluate on validation set
                model.eval()
                val_loss = 0
                with torch.no_grad():
                    for batch in val_loader:
                        reconstructed = model(batch)
                        loss = criterion(reconstructed, batch)
                        val_loss += loss.item()
                val_loss /= len(val_loader)

                print(f"Validation Loss: {val_loss:.4f}")

                if val_loss < best_loss:
                    best_loss = val_loss
                    best_model = model
                    best_params = {'hidden_size': hidden_size, 'lr': lr, 'clip': clip}

    print(f"Best Params: {best_params}, Best Validation Loss: {best_loss:.4f}")
    return best_model

# Additional Metric: Reconstruction Error (Mean Squared Error)
def calculate_mse(original, reconstructed):
    return np.mean((original - reconstructed) ** 2)

# 6. Visualization & Accuracy Calculation
def plot_examples_and_calculate_mse(original, reconstructed, num_examples=3):
    total_mse = 0
    for i in range(num_examples):
        plt.figure(figsize=(10, 4))

        # Plot original vs time
        plt.subplot(1, 2, 1)
        plt.plot(original[i], label="Original")
        plt.title(f"Original Signal {i + 1}")
        plt.xlabel("Time")
        plt.ylabel("Value")
        plt.legend()

        # Plot original and reconstructed vs time
        plt.subplot(1, 2, 2)
        plt.plot(original[i], label="Original")
        plt.plot(reconstructed[i].detach().cpu().numpy(), label="Reconstructed")
        plt.title(f"Original vs Reconstructed {i + 1}")
        plt.xlabel("Time")
        plt.ylabel("Value")
        plt.legend()

        plt.tight_layout()
        plt.show()

        # Calculate MSE for each example
        mse = calculate_mse(original[i], reconstructed[i].detach().cpu().numpy())
        total_mse += mse
        print(f"MSE for example {i + 1}: {mse:.4f}")

    avg_mse = total_mse / num_examples
    print(f"Average MSE: {avg_mse:.4f}")

    return avg_mse

#Main Script Update for Model Evaluation
if __name__ == "__main__":
    # Generate and split data
    data = generate_synthetic_data()
    train_data, val_data, test_data = split_data(data)

    # Reshape data to match the expected input format (batch_size, sequence_length, input_size)
    train_data = train_data.reshape(-1, 50, 1)  # input_size = 1 for each feature in the sequence
    val_data = val_data.reshape(-1, 50, 1)
    test_data = test_data.reshape(-1, 50, 1)

    # Grid search for hyperparameters
    hidden_sizes = [16, 32, 40]
    learning_rates = [0.1, 0.01, 1]
    gradient_clipping_values = [1, 3, 5]

    best_model = grid_search(train_data, val_data, hidden_sizes, learning_rates, gradient_clipping_values)

    # Train the best model on the full training set
    train_dataset = SequenceDataset(train_data)
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
    optimizer = optim.Adam(best_model.parameters(), lr=1e-3)
    criterion = nn.MSELoss()

    print("Training the best model on the full training set...")
    train_model(best_model, train_loader, optimizer, criterion, num_epochs=20)

    # Evaluate on the test set
    best_model.eval()
    with torch.no_grad():
        test_dataset = SequenceDataset(test_data)
        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
        original, reconstructed = [], []
        for batch in test_loader:
            reconstructed_batch = best_model(batch)
            original.append(batch[0].cpu().numpy())
            reconstructed.append(reconstructed_batch[0])

    # Plot and calculate MSE
    plot_examples_and_calculate_mse(original, reconstructed)